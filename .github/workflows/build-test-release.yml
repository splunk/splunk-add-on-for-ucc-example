# jscpd:ignore-start
name: build-test-release
on:
  push:
    branches:
      - "main"
      - "develop"
      - "test/test-do-not-delete-or-merge"
    tags:
      - "v[0-9]+.[0-9]+.[0-9]+"
  pull_request:
    branches: [main, develop]

jobs:
  compliance-sample-scanner:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: sample-scanner
        uses: splunk/addonfactory-sample-scanner@v1
        id: sample-scanner
        env:
          REVIEWDOG_GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  compliance-dependencies:
    name: compliance-dependencies
    runs-on: ubuntu-latest
    continue-on-error: true

    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: ort-action
        uses: splunk/addonfactory-ort-action@v1
        id: ort-action
        with:
          WorkDir: .
          UsePython3: "3.7"
      - name: ort-action-artifacts-reports
        uses: actions/upload-artifact@v2
        with:
          name: analysis-reports
          path: |
            .ort/reports/*
        if: always()
      - name: ort-action-artifacts-analyzer
        uses: actions/upload-artifact@v2
        with:
          name: analysis-analyzer
          path: |
            .ort/analyzer/*
        if: always()
  compliance-copyrights:
    name: compliance-copyrights
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: REUSE Compliance Check
        uses: fsfe/reuse-action@v1.1

  lint:
    runs-on: ubuntu-latest
    name: quality-lint
    continue-on-error: true
    steps:
      - uses: actions/checkout@v2
        with:
          # Full git history is needed to get a proper list of changed files within `super-linter`
          fetch-depth: 0
      - name: quality-lint
        uses: github/super-linter@v4
        env:
          VALIDATE_ALL_CODEBASE: false
          DEFAULT_BRANCH: main
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          FILTER_REGEX_EXCLUDE: README.md
  review_secrets:
    name: security-detect-secrets
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - name: Checkout
        uses: actions/checkout@v2
        with:
          submodules: false
          fetch-depth: "0"
      - name: Trufflehog Actions Scan
        uses: edplato/trufflehog-actions-scan@v0.9j-beta
        with:
          scanArguments: "--max_dept 50 -x .github/workflows/exclude-patterns.txt"

  semgrep:
    runs-on: ubuntu-latest
    name: security-sast-semgrep
    continue-on-error: true
    steps:
      - uses: actions/checkout@v2
      - name: Semgrep
        id: semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: p/r2c
  snyk:
    name: security-vuln-snyk
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v2
      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: 3.7
      - name: Get pip cache dir
        id: pip-cache
        run: |
          echo "::set-output name=dir::$(pip cache dir)"
      - name: Run Check there are libraries to scan
        id: checklibs
        run: if [ -f package/lib/requirements.txt ]; then echo "::set-output name=ENABLED::true"; fi
      - name: pip cache
        if: ${{ steps.checklibs.outputs.ENABLED == 'true' }}
        uses: actions/cache@v2
        with:
          path: ${{ steps.pip-cache.outputs.dir }}
          key: ${{ runner.os }}-pip-${{ hashFiles('package/lib/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install deps
        if: ${{ steps.checklibs.outputs.ENABLED == 'true' }}
        run: pip install -r package/lib/requirements.txt
      - uses: snyk/actions/setup@master
      - uses: actions/setup-go@v2.1.3
        with:
          go-version: "1.13"
      - name: Snyk monitor
        run: snyk test --sarif-file-output=snyk.sarif
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
  build:
    name: build
    needs:
      - review_secrets
      - snyk
      - semgrep
      - lint
      - compliance-copyrights
      - compliance-dependencies
    runs-on: ubuntu-latest
    outputs:
      buildname: ${{ steps.buildupload.outputs.name }}
    steps:
      - uses: actions/checkout@v2
        with:
          # Very Important semantic-release won't trigger a tagged
          # build if this is not set false
          persist-credentials: false
      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: 3.7
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - name: create requirements file for pip
        run: |
          if [ -f "poetry.lock" ]
          then
            echo " potery.lock found "
            sudo pip3 install poetry
            mkdir -p package/lib || true
            poetry export --without-hashes -o package/lib/requirements.txt
            poetry export --without-hashes --dev -o requirements_dev.txt
            cat requirements_dev.txt
          fi
      - name: Get pip cache dir
        id: pip-cache
        run: |
          echo "::set-output name=dir::$(pip cache dir)"
      - name: Run Check there are libraries to scan
        id: checklibs
        run: if [ -f requirements_dev.txt ]; then echo "::set-output name=ENABLED::true"; fi
      - name: pip cache
        if: ${{ steps.checklibs.outputs.ENABLED == 'true' }}
        uses: actions/cache@v2
        with:
          path: ${{ steps.pip-cache.outputs.dir }}
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements_dev.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install deps
        if: ${{ steps.checklibs.outputs.ENABLED == 'true' }}
        run: pip install -r requirements_dev.txt
      - name: Semantic Release Get Next
        id: semantic
        if: github.event_name != 'pull_request'
        uses: cycjimmy/semantic-release-action@v2.5.4
        with:
          semantic_version: 17
          extra_plugins: |
            @semantic-release/exec
            @semantic-release/git
          dry_run: true
        env:
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN_ADMIN }}
      - name: Determine the version to build
        id: BuildVersion
        uses: splunk/addonfactory-get-splunk-package-version-action@v1
        with:
          SemVer: ${{ steps.semantic.outputs.new_release_version }}
          PrNumber: ${{ github.event.number }}
      - uses: actions/download-artifact@v2
        with:
          name: analysis-reports
          path: /tmp/analysis-reports
      - name: Update Notices
        run: |
          cp -f /tmp/analysis-reports/NOTICE_default THIRDPARTY || true
          cp -f /tmp/analysis-reports/NOTICE_default package/THIRDPARTY || true
      - name: Build Package
        id: uccgen
        uses: splunk/addonfactory-ucc-generator-action@v1
        with:
          version: ${{ steps.BuildVersion.outputs.VERSION }}
      - name: Slim Package
        id: slim
        uses: splunk/addonfactory-packaging-toolkit-action@v1
        with:
          source: ${{ steps.uccgen.outputs.OUTPUT }}
      - name: artifact-splunk-unpacked
        uses: actions/upload-artifact@v2
        with:
          name: package-raw
          path: ${{ steps.uccgen.outputs.OUTPUT }}**
        if: always()
      - name: artifact-splunk-base
        uses: actions/upload-artifact@v2
        with:
          name: package-splunkbase
          path: ${{ steps.slim.outputs.OUTPUT }}
        if: always()
      - name: upload-build-to-s3
        id: buildupload
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          echo "::set-output name=name::$(basename ${{ steps.slim.outputs.OUTPUT }})"
          echo `basename ${{ steps.slim.outputs.OUTPUT }}`
          aws s3 cp ${{ steps.slim.outputs.OUTPUT }} s3://ta-dev-artifacts/ta-apps/
      - name: artifact-splunk-parts
        uses: actions/upload-artifact@v2
        with:
          name: package-deployment
          path: build/package/deployment**
        if: always()
        continue-on-error: True
  security-virustotal:
    name: security-virustotal
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/download-artifact@v2
        with:
          name: package-splunkbase
          path: build/package/

      - name: VirusTotal Scan
        uses: crazy-max/ghaction-virustotal@v2
        with:
          vt_api_key: ${{ secrets.VT_API_KEY }}
          files: |
            build/package/*
  test-inventory:
    runs-on: ubuntu-latest
    # Map a step output to a job output
    outputs:
      unit: ${{ steps.testset.outputs.unit }}
      knowledge: ${{ steps.testset.outputs.knowledge }}
      ui: ${{ steps.testset.outputs.ui }}
      modinput_functional: ${{ steps.testset.outputs.modinput_functional }}
    steps:
      - uses: actions/checkout@v2
      - id: testset
        name: testsets
        run: |
          find tests -type d -maxdepth 1 -mindepth 1 | sed 's|^tests/||g' |  while read -r TESTSET; do echo "::set-output name=$TESTSET::true"; echo "$TESTSET::true"; done
  test-unit:
    name: test-unit-python3-${{ matrix.python-version }}
    if: ${{ needs.test-inventory.outputs.unit == 'true' }}
    runs-on: ubuntu-latest
    needs:
      - build
      - test-inventory
    strategy:
      matrix:
        python-version:
          - "3.7"
    steps:
      - uses: actions/checkout@v2
      - if: failure()
        name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - uses: actions/download-artifact@v2
        with:
          name: package-raw
          path: output
      - name: Setup addon
        run: |
          if [ -f "poetry.lock" ]
           then
             mkdir -p package/lib || true
             pip install poetry
             poetry export --without-hashes -o package/lib/requirements.txt
             poetry export --without-hashes --dev -o requirements_dev.txt
           fi
          if [ ! -f requirements_dev.txt ]; then echo no requirements;exit 0 ;fi
          pip install -r requirements_dev.txt
      - name: Copy pytest ini
        run: cp tests/unit/pytest-ci.ini pytest.ini
      - name: Run Pytest with coverage
        run: pytest --cov=./ --cov-report=xml --junitxml=test-results/junit.xml tests/unit
      - name: Run Check if codecov enabled
        id: checkcodecov
        run: if [ -n "$CODECOV_TOKEN" ]; then echo "::set-output name=ENABLED::true"; fi
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
      - name: Upload coverage to Codecov
        if: ${{ steps.checkcodecov.outputs.ENABLED == 'true' }}
        uses: codecov/codecov-action@v2.0.2
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          directory: ./coverage/reports/
          env_vars: OS,PYTHON
          fail_ci_if_error: true
          path_to_write_report: ./coverage/codecov_report.txt
          verbose: true
      - uses: actions/upload-artifact@v2 # upload test results
        if: success() || failure() # run this step even if previous step failed
        with:
          name: test-results-unit-python_${{ matrix.python-version }}
          path: test-results/*

  appinspect:
    name: quality-appinspect-${{ matrix.tags }}
    needs: build
    runs-on: ubuntu-latest
    continue-on-error: true
    strategy:
      matrix:
        tags:
          - "cloud"
          - "appapproval"
          - "deprecated_feature"
          - "developer_guidance"
          - "future"
          - "self-service"
          - "splunk_appinspect"
    steps:
      - uses: actions/download-artifact@v2
        with:
          name: package-splunkbase
          path: build/package/

      - name: Scan
        uses: splunk/appinspect-cli-action@v1
        with:
          app_path: build/package/
          included_tags: ${{ matrix.tags }}

  artifact-registry:
    runs-on: ubuntu-latest
    continue-on-error: true
    needs:
      - appinspect
      - security-virustotal
    outputs:
      artifact: ${{ steps.artifactid.outputs.result }}
    steps:
      - uses: actions/checkout@v2
      - uses: actions/download-artifact@v2
        with:
          name: package-splunkbase
          path: build/package/splunkbase

      - id: getappid
        run: |
          appid=$(jq -r '.info.id.name' package/app.manifest)
          echo appid=$appid
          echo "::set-output name=result::$(echo $appid)"
      - run: |
          curl -fsSL https://raw.githubusercontent.com/fishworks/gofish/main/scripts/install.sh | bash
          gofish init
          gofish install oras
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1
      - name: Login to GitHub Packages Docker Registry
        uses: docker/login-action@v1.10.0
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Docker meta
        id: meta
        uses: docker/metadata-action@v3
        with:
          images: ghcr.io/${{ github.repository }}
          tags: |
            type=semver,pattern=v{{major}}.{{minor}},prefix=${{ steps.getappid.outputs.result }}-
            type=semver,pattern=v{{major}},prefix=${{ steps.getappid.outputs.result }}-
            type=semver,pattern=v{{version}},prefix=${{ steps.getappid.outputs.result }}-
            type=semver,pattern={{major}}.{{minor}},prefix=${{ steps.getappid.outputs.result }}-
            type=semver,pattern={{major}},prefix=${{ steps.getappid.outputs.result }}-
            type=semver,pattern={{version}},prefix=${{ steps.getappid.outputs.result }}-
            type=ref,event=branch,prefix=${{ steps.getappid.outputs.result }}-
            type=ref,event=pr,prefix=${{ steps.getappid.outputs.result }}-
            type=sha,prefix=${{ steps.getappid.outputs.result }}-
            type=sha,format=long,prefix=${{ steps.getappid.outputs.result }}-
      - name: Upload artifacts
        run: |
          tee /tmp/tags &>/dev/null <<EOF
          ${{ steps.meta.outputs.tags }}
          EOF
          pushd build/package/splunkbase/
          PACKAGE=$(ls *)
          echo $PACKAGE
          mv $PACKAGE ${{ steps.getappid.outputs.result }}.spl
          while IFS= read -r line
          do
            echo ">>$line<<"
            oras push \
                --manifest-config /dev/null:application/vnd.splunk.ent.package.v1.tar+gzip \
                $line \
                ${{ steps.getappid.outputs.result }}.spl
            echo "  complete"
          done < /tmp/tags
          popd
      - name: Output artifact locator
        id: artifactid
        run: |
          echo "::set-output name=result::$(echo ${{ fromJSON(steps.meta.outputs.json).tags[0] }})"

  setup:
    needs:
      - build
      - artifact-registry
      - test-inventory
    runs-on: ubuntu-18.04
    container:
      image: ghcr.io/splunk/workflow-engine-base:2.0.3
    outputs:
      argo-server: ${{ steps.test-setup.outputs.argo-server }}
      argo-http1: ${{ steps.test-setup.outputs.argo-http1 }}
      argo-secure: ${{ steps.test-setup.outputs.argo-secure }}
      argo-base-href: ${{ steps.test-setup.outputs.argo-base-href }}
      argo-workflow-tmpl-name: ${{ steps.test-setup.outputs.argo-workflow-tmpl-name }}
      argo-namespace: ${{ steps.test-setup.outputs.argo-namespace }}
      addon-name: ${{ steps.test-setup.outputs.addon-name }}
      job-name: ${{ steps.test-setup.outputs.job-name }}
      labels: ${{ steps.test-setup.outputs.labels }}
      addon-upload-path: ${{ steps.test-setup.outputs.addon-upload-path }}
      directory-path: ${{ steps.test-setup.outputs.directory-path }}
      s3-bucket: ${{ steps.test-setup.outputs.s3-bucket }}
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: recursive
      - name: setup for test
        id: test-setup
        run: |
          echo "::set-output name=argo-server::argo.dev.wfe.splgdi.com:443"
          echo "::set-output name=argo-http1::true"
          echo "::set-output name=argo-secure::true"
          echo "::set-output name=argo-base-href::\'\'"
          echo "::set-output name=argo-namespace::workflows"
          echo "::set-output name=argo-workflow-tmpl-name::ta-workflow"

          ADDON_NAME=$(crudini --get package/default/app.conf id name)
          ADDON_NAME=`echo ${ADDON_NAME} | awk -F 'Splunk_TA_' '{print $2}'`
          echo "::set-output name=addon-name::$(echo "$ADDON_NAME" | tr '[:lower:]' '[:upper:]')"

          JOB_NAME=${GITHUB_RUN_NUMBER}-${GITHUB_RUN_ID}
          JOB_NAME=`echo $JOB_NAME | sed "s/[_.]/-/g"`
          echo "::set-output name=job-name::$(echo $JOB_NAME)"

          LABELS="addon-name=${ADDON_NAME}"
          echo "::set-output name=labels::$(echo $LABELS)"

          ADDON_UPLOAD_PATH="s3://ta-dev-artifacts/ta-apps/${{ needs.build.outputs.buildname }}"
          echo "::set-output name=addon-upload-path::$(echo $ADDON_UPLOAD_PATH)"
          echo "::set-output name=directory-path::/tmp"
          echo "::set-output name=s3-bucket::ta-dev-artifacts"
      - name: check ENV
        env:
          STEPS: ${{ toJson(steps) }}
        run: |
          echo $STEPS
          echo "splunk-version:" ${{ steps.test-setup.outputs.splunk-version }}
          echo "addon-name:" ${{ steps.test-setup.outputs.addon-name }}
          echo "job-name:" ${{ steps.test-setup.outputs.job-name }}
          echo "labels:" ${{ steps.test-setup.outputs.labels }}
          echo "addon-upload-path:" ${{ steps.test-setup.outputs.addon-upload-path }}

  run-knowledge-tests:
    if: ${{ needs.test-inventory.outputs.knowledge == 'true' }}
    needs:
      - build
      - artifact-registry
      - test-inventory
      - setup
    runs-on: ubuntu-18.04
    strategy:
      matrix:
        splunk-version: ['8.0', '8.1', '8.2']
    container:
      image: ghcr.io/splunk/workflow-engine-base:2.0.3
    env:
      ARGO_SERVER: ${{ needs.setup.outputs.argo-server }}
      ARGO_HTTP1: ${{ needs.setup.outputs.argo-http1 }}
      ARGO_SECURE: ${{ needs.setup.outputs.argo-secure }}
      ARGO_BASE_HREF: ${{ needs.setup.outputs.argo-href }}
      ARGO_NAMESPACE: ${{ needs.setup.outputs.argo-namespace }}
      SPLUNK_VERSION_BASE: ${{ matrix.splunk-version }}
      TEST_TYPE: "knowledge"
      TEST_ARGS: ""
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: recursive
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_DEFAULT_REGION }}
      - name: Read secrets from AWS Secrets Manager into environment variables
        id: get-argo-token
        run: |
          ARGO_TOKEN=`aws secretsmanager get-secret-value --secret-id ta-dev-github-workflow-automation-token | jq -r '.SecretString'`
          echo "::set-output name=argo-token::$(echo $ARGO_TOKEN)"
      - name: create job name
        id: create-job-name
        run: |
          RANDOM_STRING=`head -3 /dev/urandom | tr -cd '[:lower:]' | cut -c -4`
          JOB_NAME=${{ needs.setup.outputs.job-name }}-${RANDOM_STRING}
          JOB_NAME=`echo $JOB_NAME | sed "s/[_.]/-/g"`
          echo "::set-output name=job-name::$(echo $JOB_NAME)"
      - name: get version
        id: get-version
        run: |
          echo "Fetching Splunk Version to test"
          SPLUNK_VERSION=$(crudini --get deps/build/addonfactory_test_matrix_splunk/splunk_matrix.conf "${SPLUNK_VERSION_BASE}" VERSION)
          echo "::set-output name=splunk-version::$(echo $SPLUNK_VERSION)"
      - name: run-tests
        id: run-tests
        env:
          ARGO_TOKEN: ${{ steps.get-argo-token.outputs.argo-token }}
        uses: splunk/wfe-test-runner-action@test/try-lukasz
        with:
          splunk: ${{ steps.get-version.outputs.splunk-version }}
          test-type: ${{ env.TEST_TYPE }}
          test-args: ''
          job-name: ${{ steps.create-job-name.outputs.job-name }}
          labels: ${{ needs.setup.outputs.labels }}
          workflow-tmpl-name: ${{ needs.setup.outputs.argo-workflow-tmpl-name }}
          workflow-template-ns: ${{ needs.setup.outputs.argo-namespace }}
          destroy-setup: 'Yes'
          addon-url: ${{ needs.setup.outputs.addon-upload-path }}
          addon-secret-id: ADD_ON_${{ needs.setup.outputs.addon-name }}
      - name: check if workflow completed
        env:
          ARGO_TOKEN: ${{ steps.get-argo-token.outputs.argo-token }}
        if: always()
        run: |
          until argo watch ${{ steps.run-tests.outputs.workflow-name }} -n workflows > /dev/null; do echo "argo watch ended with failure $?. Trying again"; sleep 60; done
          argo watch ${{ steps.run-tests.outputs.workflow-name }} -n workflows
      - name: pull artifacts from s3 bucket
        if: always()
        run: |
          echo "pulling artifacts"
          aws s3 cp s3://${{ needs.setup.outputs.s3-bucket }}/artifacts-${{ steps.create-job-name.outputs.job-name }}/${{ steps.create-job-name.outputs.job-name }}.tgz ${{ needs.setup.outputs.directory-path }}/
          tar -xf ${{ needs.setup.outputs.directory-path }}/${{ steps.create-job-name.outputs.job-name }}.tgz -C ${{ needs.setup.outputs.directory-path }}
          ls -al ${{ needs.setup.outputs.directory-path }}
          ls -al ${{ needs.setup.outputs.directory-path }}/test-results
      - name: pull logs from s3 bucket
        if: always()
        run: |
          echo "pulling logs"
          mkdir -p ${{ needs.setup.outputs.directory-path }}/argo-logs
          aws s3 cp s3://${{ needs.setup.outputs.s3-bucket }}/${{ steps.run-tests.outputs.workflow-name }}/ ${{ needs.setup.outputs.directory-path }}/argo-logs/ --recursive
      - uses: actions/upload-artifact@v2.2.4
        if: always()
        with:
          name: archive splunk ${{ steps.get-version.outputs.splunk-version }} ${{ env.TEST_TYPE }} tests artifacts
          path: |
            ${{ needs.setup.outputs.directory-path }}/test-results
      - uses: actions/upload-artifact@v2.2.4
        if: always()
        with:
          name: archive splunk ${{ steps.get-version.outputs.splunk-version }} ${{ env.TEST_TYPE }} tests logs
          path: |
            ${{ needs.setup.outputs.directory-path }}/argo-logs
      - name: Test Report
        uses: dorny/test-reporter@v1
        continue-on-error: true
        if: always()
        with:
          name: splunk ${{ steps.get-version.outputs.splunk-version }} ${{ env.TEST_TYPE }} test report
          path: '${{ needs.setup.outputs.directory-path }}/test-results/*.xml'
          reporter: java-junit

  run-ui-tests:
    if: ${{ needs.test-inventory.outputs.ui == 'true' }}
    needs:
      - build
      - artifact-registry
      - test-inventory
      - setup
    runs-on: ubuntu-18.04
    strategy:
      matrix:
        splunk-version: ['8.0', '8.1', '8.2']
        browser: ['chrome', 'firefox', 'safari']
    container:
      image: ghcr.io/splunk/workflow-engine-base:2.0.3
    env:
      ARGO_SERVER: ${{ needs.setup.outputs.argo-server }}
      ARGO_HTTP1: ${{ needs.setup.outputs.argo-http1 }}
      ARGO_SECURE: ${{ needs.setup.outputs.argo-secure }}
      ARGO_BASE_HREF: ${{ needs.setup.outputs.argo-href }}
      ARGO_NAMESPACE: ${{ needs.setup.outputs.argo-namespace }}
      SPLUNK_VERSION_BASE: ${{ matrix.splunk-version }}
      TEST_TYPE: "ui"
      TEST_ARGS: "--browser ${{ matrix.browser }}"
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: recursive
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_DEFAULT_REGION }}
      - name: Read secrets from AWS Secrets Manager into environment variables
        id: get-argo-token
        run: |
          ARGO_TOKEN=`aws secretsmanager get-secret-value --secret-id ta-dev-github-workflow-automation-token | jq -r '.SecretString'`
          echo "::set-output name=argo-token::$(echo $ARGO_TOKEN)"
      - name: create job name
        id: create-job-name
        run: |
          RANDOM_STRING=`head -3 /dev/urandom | tr -cd '[:lower:]' | cut -c -4`
          JOB_NAME=${{ needs.setup.outputs.job-name }}-${RANDOM_STRING}
          JOB_NAME=`echo $JOB_NAME | sed "s/[_.]/-/g"`
          echo "::set-output name=job-name::$(echo $JOB_NAME)"
      - name: get version
        id: get-version
        run: |
          echo "Fetching Splunk Version to test"
          SPLUNK_VERSION=$(crudini --get deps/build/addonfactory_test_matrix_splunk/splunk_matrix.conf "${SPLUNK_VERSION_BASE}" VERSION)
          echo "::set-output name=splunk-version::$(echo $SPLUNK_VERSION)"
      - name: run-tests
        id: run-tests
        env:
          ARGO_TOKEN: ${{ steps.get-argo-token.outputs.argo-token }}
        uses: splunk/wfe-test-runner-action@test/try-lukasz
        with:
          splunk: ${{ steps.get-version.outputs.splunk-version }}
          test-type: ${{ env.TEST_TYPE }}
          test-args: ${{ env.TEST_ARGS }}
          job-name: ${{ steps.create-job-name.outputs.job-name }}
          labels: ${{ needs.setup.outputs.labels }}
          workflow-tmpl-name: ${{ needs.setup.outputs.argo-workflow-tmpl-name }}
          workflow-template-ns: ${{ needs.setup.outputs.argo-namespace }}
          destroy-setup: 'Yes'
          addon-url: ${{ needs.setup.outputs.addon-upload-path }}
          addon-secret-id: ADD_ON_${{ needs.setup.outputs.addon-name }}
      - name: check if workflow completed
        if: always()
        env:
          ARGO_TOKEN: ${{ steps.get-argo-token.outputs.argo-token }}
        run: |
          until argo watch ${{ steps.run-tests.outputs.workflow-name }} -n workflows > /dev/null; do echo "argo watch ended with failure $?. Trying again"; sleep 60; done
          argo watch ${{ steps.run-tests.outputs.workflow-name }} -n workflows
      - name: pull artifacts from s3 bucket
        if: always()
        run: |
          echo "pulling artifacts"
          aws s3 cp s3://${{ needs.setup.outputs.s3-bucket }}/artifacts-${{ steps.create-job-name.outputs.job-name }}/${{ steps.create-job-name.outputs.job-name }}.tgz ${{ needs.setup.outputs.directory-path }}/
          tar -xf ${{ needs.setup.outputs.directory-path }}/${{ steps.create-job-name.outputs.job-name }}.tgz -C ${{ needs.setup.outputs.directory-path }}
          ls -al ${{ needs.setup.outputs.directory-path }}
          ls -al ${{ needs.setup.outputs.directory-path }}/test-results
      - name: pull logs from s3 bucket
        if: always()
        run: |
          echo "pulling logs"
          mkdir -p ${{ needs.setup.outputs.directory-path }}/argo-logs
          aws s3 cp s3://${{ needs.setup.outputs.s3-bucket }}/${{ steps.run-tests.outputs.workflow-name }}/ ${{ needs.setup.outputs.directory-path }}/argo-logs/ --recursive
      - uses: actions/upload-artifact@v2.2.4
        if: always()
        with:
          name: archive splunk ${{ steps.get-version.outputs.splunk-version }} ${{ env.TEST_TYPE }} tests artifacts
          path: |
            ${{ needs.setup.outputs.directory-path }}/test-results
      - uses: actions/upload-artifact@v2.2.4
        if: always()
        with:
          name: archive splunk ${{ steps.get-version.outputs.splunk-version }} ${{ env.TEST_TYPE }} ${{ matrix.browser }} tests logs
          path: |
            ${{ needs.setup.outputs.directory-path }}/argo-logs
      - name: Test Report
        uses: dorny/test-reporter@v1
        continue-on-error: true
        if: always()
        with:
          name: splunk ${{ steps.get-version.outputs.splunk-version }} ${{ env.TEST_TYPE }} ${{ matrix.browser }} test report
          path: '${{ needs.setup.outputs.directory-path }}/test-results/*.xml'
          reporter: java-junit

  run-modinput-tests:
    if: ${{ needs.test-inventory.outputs.modinput_functional == 'true' }}
    needs:
      - build
      - artifact-registry
      - test-inventory
      - setup
    runs-on: ubuntu-18.04
    strategy:
      matrix:
        splunk-version: ['8.0', '8.1', '8.2']
        modinput-type: ['modinput_functional']
    container:
      image: ghcr.io/splunk/workflow-engine-base:2.0.3
    env:
      ARGO_SERVER: ${{ needs.setup.outputs.argo-server }}
      ARGO_HTTP1: ${{ needs.setup.outputs.argo-http1 }}
      ARGO_SECURE: ${{ needs.setup.outputs.argo-secure }}
      ARGO_BASE_HREF: ${{ needs.setup.outputs.argo-href }}
      ARGO_NAMESPACE: ${{ needs.setup.outputs.argo-namespace }}
      SPLUNK_VERSION_BASE: ${{ matrix.splunk-version }}
      TEST_TYPE: "modinput_functional"
      TEST_ARGS: ""
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: recursive
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_DEFAULT_REGION }}
      - name: Read secrets from AWS Secrets Manager into environment variables
        id: get-argo-token
        run: |
          ARGO_TOKEN=`aws secretsmanager get-secret-value --secret-id ta-dev-github-workflow-automation-token | jq -r '.SecretString'`
          echo "::set-output name=argo-token::$(echo $ARGO_TOKEN)"
      - name: create job name
        id: create-job-name
        run: |
          RANDOM_STRING=`head -3 /dev/urandom | tr -cd '[:lower:]' | cut -c -4`
          JOB_NAME=${{ needs.setup.outputs.job-name }}-${RANDOM_STRING}
          JOB_NAME=`echo $JOB_NAME | sed "s/[_.]/-/g"`
          echo "::set-output name=job-name::$(echo $JOB_NAME)"
      - name: get version
        id: get-version
        run: |
          echo "Fetching Splunk Version to test"
          SPLUNK_VERSION=$(crudini --get deps/build/addonfactory_test_matrix_splunk/splunk_matrix.conf "${SPLUNK_VERSION_BASE}" VERSION)
          echo "::set-output name=splunk-version::$(echo $SPLUNK_VERSION)"
      - name: run-tests
        id: run-tests
        env:
          ARGO_TOKEN: ${{ steps.get-argo-token.outputs.argo-token }}
        uses: splunk/wfe-test-runner-action@test/try-lukasz
        with:
          splunk: ${{ steps.get-version.outputs.splunk-version }}
          test-type: ${{ env.TEST_TYPE }}
          test-args: ${{ env.TEST_ARGS }}
          job-name: ${{ steps.create-job-name.outputs.job-name }}
          labels: ${{ needs.setup.outputs.labels }}
          workflow-tmpl-name: ${{ needs.setup.outputs.argo-workflow-tmpl-name }}
          workflow-template-ns: ${{ needs.setup.outputs.argo-namespace }}
          destroy-setup: 'Yes'
          addon-url: ${{ needs.setup.outputs.addon-upload-path }}
          addon-secret-id: ADD_ON_${{ needs.setup.outputs.addon-name }}
      - name: check if workflow completed
        if: always()
        env:
          ARGO_TOKEN: ${{ steps.get-argo-token.outputs.argo-token }}
        run: |
          until argo watch ${{ steps.run-tests.outputs.workflow-name }} -n workflows > /dev/null; do echo "argo watch ended with failure $?. Trying again"; sleep 60; done
          argo watch ${{ steps.run-tests.outputs.workflow-name }} -n workflows
      - name: pull artifacts from s3 bucket
        if: always()
        run: |
          echo "pulling artifacts"
          aws s3 cp s3://${{ needs.setup.outputs.s3-bucket }}/artifacts-${{ steps.create-job-name.outputs.job-name }}/${{ steps.create-job-name.outputs.job-name }}.tgz ${{ needs.setup.outputs.directory-path }}/
          tar -xf ${{ needs.setup.outputs.directory-path }}/${{ steps.create-job-name.outputs.job-name }}.tgz -C ${{ needs.setup.outputs.directory-path }}
          ls -al ${{ needs.setup.outputs.directory-path }}
          ls -al ${{ needs.setup.outputs.directory-path }}/test-results
      - name: pull logs from s3 bucket
        if: always()
        run: |
          echo "pulling logs"
          mkdir -p ${{ needs.setup.outputs.directory-path }}/argo-logs
          aws s3 cp s3://${{ needs.setup.outputs.s3-bucket }}/${{ steps.run-tests.outputs.workflow-name }}/ ${{ needs.setup.outputs.directory-path }}/argo-logs/ --recursive
      - uses: actions/upload-artifact@v2.2.4
        if: always()
        with:
          name: archive splunk ${{ steps.get-version.outputs.splunk-version }} ${{ env.TEST_TYPE }} tests artifacts
          path: |
            ${{ needs.setup.outputs.directory-path }}/test-results
      - uses: actions/upload-artifact@v2.2.4
        if: always()
        with:
          name: archive splunk ${{ steps.get-version.outputs.splunk-version }} ${{ env.TEST_TYPE }} tests logs
          path: |
            ${{ needs.setup.outputs.directory-path }}/argo-logs
      - name: Test Report
        uses: dorny/test-reporter@v1
        continue-on-error: true
        if: always()
        with:
          name: splunk ${{ steps.get-version.outputs.splunk-version }} ${{ env.TEST_TYPE }} test report
          path: '${{ needs.setup.outputs.directory-path }}/test-results/*.xml'
          reporter: java-junit

  update-semver:
    name: release-set-git-tags
    if: startsWith(github.ref, 'refs/tags/v')
    needs:
      - test-unit
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: haya14busa/action-update-semver@v1
# jscpd:ignore-end
